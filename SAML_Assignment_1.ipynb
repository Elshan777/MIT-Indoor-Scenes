{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAML Assignment 1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elshan777/MIT-Indoor-Scenes/blob/master/SAML_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xPfgTCxpev8"
      },
      "source": [
        "# Assignment 1 - Image Classification\n",
        "\n",
        "This notebook contains the required task for the first assignment of the Software for Advanced Machine Learning course. Read the task description and implement the empty code cells. Each section represents a stage along implementing an image classifier, from loading and inspecting the dataset to training a **pre-trained** Convolutional Neural Network architecture. The sections are to guide you but you do not have to follow that specific order. \n",
        "\n",
        "Copy this notebook to your drive (File -> Save a copy in Drive), edit it and upload the final ipynb file to [Canvas](https://canvas.elte.hu) or upload the link to the Colab notebook itself. If you have your own machine with Jupyter installed, you can work there as well.\n",
        "\n",
        "**Note** Make sure the notebook is using GPU accelerataion in Edit -> Notebook settings, otherwise training and evaluation can be very slow.\n",
        "\n",
        "## Rules and Comments\n",
        "- From the list of datasets and architectures listed in canvas, each student was atributed **1 dataset and 1 architecture** to use within this assignment. Please confirm yours in the Canvas assignment's description. \n",
        "- This is an DL class so to pass the homework you do have to implement a working classifier, just loading the data or having a \"random-guess\" performance is not enough.\n",
        "- As always, copying others' code will make you fail the homework automatically (and thus the course). Remember that you will have to defend the assignment at the end of the semester.\n",
        "- **Deadline is March 25**\n",
        "- Make sure your code can be run from an empty state (use Runtime -> Run all in the menu after restarting the notebook)\n",
        "- Feel free to add more code cells as needed. But don't put code into external Python files to ease the reviewing.\n",
        "- Please add your name and Neptun ID below for easier identification.\n",
        "\n",
        "**Name: Elshan Gadimov** \n",
        "\n",
        "**Neptun ID: OV7MIK** \n",
        "\n",
        "## Task description\n",
        "Your task is to train an already pretrained Convolutional Neural Network architecture on a dataset, both given in canvas. The datasets contain images as input and class labels as target, thus you have to solve a Supervised Machine Learning Classification problem. \n",
        "\n",
        "The dataset shoud be divided into train, validation and test set, for which results should be presented for all.\n",
        "\n",
        "You can either train the architecture you were given without changing its layers, or you can add more layers, if you believe it increases the accuracy. There is no expected percentage of accuracy, but **your accuracy should be better than random guessing and your loss has to decrease throughout the epochs**. We expect you to show visualisations (any of the following: matplotlib, seaborn, tensorboard, ...) of the accuracy and loss and use Early stopping while training your network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR0con3OuFBM"
      },
      "source": [
        "## 0. Import libraries\n",
        "Import all libraries/packages that you believe will help you fulfil the task, but **for the network only PyTorch can be used.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyGWby4VpNMC"
      },
      "source": [
        "# ADD YOUR CODE HERE\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1tucmxFuklk"
      },
      "source": [
        "## 1. Dataset \n",
        "Load the dataset you were given. Images should be stored in an X variable and your labels in a Y variable. Split your dataset into train, validation and test set and pre-process your data for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ossmpkq9vfrL"
      },
      "source": [
        "#### Loading the dataset\n",
        "Show some images and labels of your dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "eDPTJOa4zTfM",
        "outputId": "29c1ccd5-060a-4eb5-be6c-de2b4855c72d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "tl33KnNfzXYm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download itsahmad/indoor-scenes-cvpr-2019"
      ],
      "metadata": {
        "id": "vesVFQpvzgIo",
        "outputId": "426dae9c-c240-462b-fe2b-d4ff2c8c56cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading indoor-scenes-cvpr-2019.zip to /content\n",
            " 99% 2.31G/2.34G [01:03<00:00, 39.3MB/s]\n",
            "100% 2.34G/2.34G [01:03<00:00, 39.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip indoor-scenes-cvpr-2019"
      ],
      "metadata": {
        "id": "tiLvadLb0bim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the data\n",
        "data_dir  = '/content/indoorCVPR_09/Images'\n",
        "\n",
        "classes = os.listdir(data_dir)\n",
        "print(classes)\n",
        "print(len(classes), \"Existing classes\")"
      ],
      "metadata": {
        "id": "f9Ndz8Tu1DPq",
        "outputId": "242f5b2d-9a78-4375-caf8-7708ef6d5e39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['casino', 'studiomusic', 'movietheater', 'warehouse', 'mall', 'florist', 'concert_hall', 'closet', 'prisoncell', 'hairsalon', 'grocerystore', 'gym', 'dentaloffice', 'restaurant', 'inside_bus', 'trainstation', 'bedroom', 'auditorium', 'kindergarden', 'pantry', 'buffet', 'bathroom', 'cloister', 'computerroom', 'lobby', 'laboratorywet', 'operating_room', 'meeting_room', 'nursery', 'classroom', 'museum', 'shoeshop', 'jewelleryshop', 'bakery', 'greenhouse', 'videostore', 'waitingroom', 'elevator', 'fastfood_restaurant', 'gameroom', 'laundromat', 'restaurant_kitchen', 'tv_studio', 'children_room', 'kitchen', 'library', 'corridor', 'toystore', 'dining_room', 'airport_inside', 'church_inside', 'office', 'artstudio', 'deli', 'inside_subway', 'clothingstore', 'bookstore', 'locker_room', 'bar', 'poolinside', 'livingroom', 'winecellar', 'garage', 'hospitalroom', 'bowling', 'stairscase', 'subway']\n",
            "67 Existing classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ng7Hn_gul3J"
      },
      "source": [
        "# ADD YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmC8EUVFv0rj"
      },
      "source": [
        "#### Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uMNfQ7sv46r"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzvWV5SFv4Ml"
      },
      "source": [
        "#### Pre-processing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4G98dyQv20o"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG9jrKpRw-xN"
      },
      "source": [
        "## 2. Convolutional Neural Network Architecture\n",
        "Load the CNN architecture you were given using pretrained weights. Define the optimizer and loss function. Train your network and save it. Remember to use Early stopping and show results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sgTC3NxxxRx"
      },
      "source": [
        "#### Load the architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAmr4k_Rx3QF"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDmjzUaax3lH"
      },
      "source": [
        "#### Define your optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXzld7Pwx8Md"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbYtFGbXx7iP"
      },
      "source": [
        "#### Train your network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRpJtn_zxDTG"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vyv_TOryBnE"
      },
      "source": [
        "#### Show results (accuracy and loss) on training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_iK_hs8yHQ7"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wL-oYMJyKAU"
      },
      "source": [
        "## 3. Conclusion (Evaluation)\n",
        "Load your trained CNN and evaluate it on the test set. Show some predictions on the test set (3 is enough) by ploting the image and printing the prediction and ground truth.\n",
        "\n",
        "How good are your results? Do you think the network is overfitted or underfitted? If yes, what do you think lead to that? If not, justify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91bFm41IzLMr"
      },
      "source": [
        "#### Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urDwdgZUyMZQ"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYwVBU9LzOHN"
      },
      "source": [
        "#### Show some predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNV0J9LKzPse"
      },
      "source": [
        "# ADD YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sFvmHPRzQSI"
      },
      "source": [
        "#### Answer the questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOJyd-sMzR-a"
      },
      "source": [
        "# ADD YOUR ANSWERS HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}